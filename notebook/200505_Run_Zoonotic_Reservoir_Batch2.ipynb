{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN: SARS-CoV-2 Zoonotic Reservoir II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Lead     : ababaian\n",
    "Issue    : #55\n",
    "Version  : \n",
    "start    : 2020 05 07\n",
    "complete : YYYY MM DD\n",
    "files    : ~/serratus/notebook/200505_ab/\n",
    "s3_files : s3://serratus-public/notebook/200505_ab/\n",
    "output   : s3://serratus-public/out/200505_zoonotic/\n",
    "```\n",
    "\n",
    "Continuation from `200505_Run_Zoonotic_Reservoir.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May  7 13:03:43 PDT 2020\r\n"
     ]
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize local workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8d4bca2cdb3cec67593847bed0cb7369cfe5b9f9\r\n"
     ]
    }
   ],
   "source": [
    "# Serratus commit version\n",
    "SERRATUS=\"/home/artem/serratus\"\n",
    "cd $SERRATUS\n",
    "git rev-parse HEAD # commit version\n",
    "\n",
    "# Create local run directory\n",
    "WORK=\"$SERRATUS/notebook/200505_ab\"\n",
    "mkdir -p $WORK; cd $WORK\n",
    "\n",
    "# SRA RunInfo Table for run -- use first 500 from Zoonotic pilot\n",
    "RUNINFO=\"$SERRATUS/notebook/200505_ab/zoonotic_SraRunInfo.csv\"\n",
    "\n",
    "head -n 10000 $RUNINFO > batch2_zoonotic.csv\n",
    "sed -i '2,5000d' batch2_zoonotic.csv\n",
    "RUNINFO=\"$WORK/batch2_zoonotic.csv\"\n",
    "\n",
    "#head $RUNINFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "mkdir -p $WORK; cd $WORK\n",
    "\n",
    "# SRA RunInfo Table for run -- use first 500 from Zoonotic pilot\n",
    "RUNINFO=\"$SERRATUS/notebook/200505_ab/zoonotic_SraRunInfo.csv\"\n",
    "\n",
    "head -n 15000 $RUNINFO > batch3_zoonotic.csv\n",
    "sed -i '2,10000d' batch3_zoonotic.csv\n",
    "RUNINFO=\"$WORK/batch3_zoonotic.csv\"\n",
    "\n",
    "#head $RUNINFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "mkdir -p $WORK; cd $WORK\n",
    "\n",
    "# SRA RunInfo Table for run -- use first 500 from Zoonotic pilot\n",
    "RUNINFO=\"$SERRATUS/notebook/200505_ab/zoonotic_SraRunInfo.csv\"\n",
    "\n",
    "head -n 20000 $RUNINFO > batch4_zoonotic.csv\n",
    "sed -i '2,15000d' batch4_zoonotic.csv\n",
    "echo \"$WORK/batch4_zoonotic.csv\"\n",
    "\n",
    "#head $RUNINFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/artem/serratus/notebook/200505_ab/batch5_zoonotic.csv\r\n"
     ]
    }
   ],
   "source": [
    "mkdir -p $WORK; cd $WORK\n",
    "\n",
    "# SRA RunInfo Table for run -- for O/N run\n",
    "RUNINFO=\"$SERRATUS/notebook/200505_ab/zoonotic_SraRunInfo.csv\"\n",
    "\n",
    "head -n 30000 $RUNINFO > batch5_zoonotic.csv\n",
    "sed -i '2,20000d' batch5_zoonotic.csv\n",
    "echo \"$WORK/batch5_zoonotic.csv\"\n",
    "\n",
    "#head $RUNINFO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terraform Initialization\n",
    "\n",
    "Go back to `r5.large` for downloaders to mitigate memory leak. It's inconsistent when it happens, kind of strange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff --git a/terraform/main/main.tf b/terraform/main/main.tf\r\n",
      "index a52496e..606aa6c 100644\r\n",
      "--- a/terraform/main/main.tf\r\n",
      "+++ b/terraform/main/main.tf\r\n",
      "@@ -109,12 +109,12 @@ module \"download\" {\r\n",
      "   source             = \"../worker\"\r\n",
      " \r\n",
      "   desired_size       = 0\r\n",
      "-  max_size           = 256\r\n",
      "+  max_size           = 200\r\n",
      " \r\n",
      "   dev_cidrs          = var.dev_cidrs\r\n",
      "   security_group_ids = [aws_security_group.internal.id]\r\n",
      " \r\n",
      "-  instance_type      = \"c5.large\" // Mitigate the memory leak in fastq-dump\r\n",
      "+  instance_type      = \"r5.large\" // Mitigate the memory leak in fastq-dump\r\n",
      "   volume_size        = 50 // Mitigate the storage leak in fastq-dump\r\n",
      "   spot_price         = 0.05\r\n",
      " \r\n",
      "@@ -134,7 +134,7 @@ module \"align\" {\r\n",
      "   source             = \"../worker\"\r\n",
      " \r\n",
      "   desired_size       = 0\r\n",
      "-  max_size           = 256\r\n",
      "+  max_size           = 500\r\n",
      "   dev_cidrs          = var.dev_cidrs\r\n",
      "   security_group_ids = [aws_security_group.internal.id]\r\n",
      "   instance_type      = \"c5.large\" # c5.large\r\n"
     ]
    }
   ],
   "source": [
    "# Terraform customization\n",
    "git diff $SERRATUS/terraform/main/main.tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mInitializing modules...\u001b[0m\r\n",
      "\r\n",
      "\u001b[0m\u001b[1mInitializing the backend...\u001b[0m\r\n",
      "\r\n",
      "\u001b[0m\u001b[1mInitializing provider plugins...\u001b[0m\r\n",
      "\r\n",
      "\u001b[0m\u001b[1m\u001b[32mTerraform has been successfully initialized!\u001b[0m\u001b[32m\u001b[0m\r\n",
      "\u001b[0m\u001b[32m\r\n",
      "You may now begin working with Terraform. Try running \"terraform plan\" to see\r\n",
      "any changes that are required for your infrastructure. All Terraform commands\r\n",
      "should now work.\r\n",
      "\r\n",
      "If you ever set or change modules or backend configuration for Terraform,\r\n",
      "rerun this command to reinitialize your working directory. If you forget, other\r\n",
      "commands will detect it and remind you to do so if necessary.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Initialize terraform\n",
    "TF=$SERRATUS/terraform/main\n",
    "cd $TF\n",
    "terraform init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mmodule.merge.data.aws_ami.amazon_linux_2: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.iam_role.aws_iam_role.role: Refreshing state... [id=SerratusIamRole-scheduler]\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role.role: Refreshing state... [id=SerratusIamRole-serratus-dl]\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket.work: Refreshing state... [id=tf-serratus-work-20200507150844714600000001]\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.data.aws_ami.amazon_linux_2: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.data.aws_ami.amazon_linux_2: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.data.aws_region.current: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_cloudwatch_log_group.scheduler: Refreshing state... [id=scheduler]\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.data.aws_ami.ecs: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1maws_security_group.internal: Refreshing state... [id=sg-09ce35f5ef14d9384]\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.data.aws_availability_zones.all: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.data.aws_region.current: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.data.aws_availability_zones.all: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_cloudwatch_log_group.g: Refreshing state... [id=serratus-dl]\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.data.aws_region.current: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.data.aws_availability_zones.all: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.data.aws_ami.amazon_linux_2: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.data.aws_region.current: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_instance_profile.profile: Refreshing state... [id=profile-serratus-dl]\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.iam_role.aws_iam_instance_profile.profile: Refreshing state... [id=profile-scheduler]\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_instance.scheduler: Refreshing state... [id=i-0cc5263666129b273]\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_eip.sch: Refreshing state... [id=eipalloc-0720a99b224a4f36f]\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_launch_configuration.worker: Refreshing state... [id=serratus-dl-20200507150922838300000008]\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_group.worker: Refreshing state... [id=serratus-dl-20200507150922838300000008]\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_cloudwatch_log_group.g: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role.task_role: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_iam_role_policy.scheduler: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role.instance_role: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.ec2Describe: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.ec2Terminate: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.AdjustAutoScaling: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role.role: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creation complete after 0s [id=SerratusIamRole-serratus-dl-20200507200447069000000001]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role.task_role: Creation complete after 0s [id=SerratusIamRole-monitor]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_iam_role_policy.scheduler: Creation complete after 0s [id=SerratusIamRole-scheduler:DescribeInstances-scheduler]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role.role: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.AdjustAutoScaling: Creation complete after 1s [id=SerratusIamRole-serratus-dl:AdjustAutoScaling-serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_cloudwatch_log_group.g: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.ec2Describe: Creation complete after 1s [id=SerratusIamRole-serratus-dl:DescribeEC2Instances-serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_cluster.monitor: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role.role: Creation complete after 1s [id=SerratusIamRole-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.ec2Terminate: Creation complete after 1s [id=SerratusIamRole-serratus-dl:TerminateEC2Instances-serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role_policy.cloudwatch: Creation complete after 1s [id=SerratusIamRole-serratus-dl:CloudWatchLogsCreate-serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.iam_role.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role.instance_role: Creation complete after 1s [id=SerratusEcsInstanceRole]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_instance.scheduler: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy_attachment.attachment: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket.work: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_instance_profile.profile: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_cloudwatch_log_group.g: Creation complete after 1s [id=serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role.role: Creation complete after 0s [id=SerratusIamRole-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.iam_role.aws_iam_role_policy.cloudwatch: Creation complete after 0s [id=SerratusIamRole-scheduler:CloudWatchLogsCreate-scheduler]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_instance_profile.monitor: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy.cloudwatch: Creation complete after 1s [id=SerratusIamRole-monitor:CloudwatchGetMetrics]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy_attachment.instance_attachment: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy_attachment.attachment: Creation complete after 1s [id=SerratusIamRole-monitor-20200507200448163200000003]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_instance_profile.profile: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role_policy.cloudwatch: Creation complete after 1s [id=SerratusIamRole-serratus-align:CloudWatchLogsCreate-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_cloudwatch_log_group.g: Creation complete after 1s [id=serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_instance_profile.profile: Creation complete after 1s [id=profile-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.ec2Describe: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creation complete after 1s [id=SerratusIamRole-serratus-align-20200507200448749700000004]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.AdjustAutoScaling: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy_attachment.instance_attachment: Creation complete after 0s [id=SerratusEcsInstanceRole-20200507200448922800000005]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.ec2Terminate: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creation complete after 0s [id=SerratusIamRole-serratus-merge-20200507200449035600000006]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.ec2Terminate: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role_policy.cloudwatch: Creation complete after 1s [id=SerratusIamRole-serratus-merge:CloudWatchLogsCreate-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.AdjustAutoScaling: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_instance_profile.monitor: Creation complete after 2s [id=profile-serratus-monitor]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.ec2Describe: Creation complete after 1s [id=SerratusIamRole-serratus-align:DescribeEC2Instances-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.ec2Describe: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_instance_profile.profile: Creation complete after 1s [id=profile-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.AdjustAutoScaling: Creation complete after 1s [id=SerratusIamRole-serratus-align:AdjustAutoScaling-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.ec2Terminate: Creation complete after 1s [id=SerratusIamRole-serratus-align:TerminateEC2Instances-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.ec2Terminate: Creation complete after 1s [id=SerratusIamRole-serratus-merge:TerminateEC2Instances-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.AdjustAutoScaling: Creation complete after 0s [id=SerratusIamRole-serratus-merge:AdjustAutoScaling-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.ec2Describe: Creation complete after 1s [id=SerratusIamRole-serratus-merge:DescribeEC2Instances-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket.work: Creation complete after 6s [id=tf-serratus-work-20200507200447766300000002]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.s3_write: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.s3_delete[0]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.s3_write: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"fq-blocks\"]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"out\"]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.s3_write: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"bam-blocks\"]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.s3_delete[0]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"fq-blocks\"]: Creation complete after 1s [id=tf-serratus-work-20200507200447766300000002:prefix-fq-blocks]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.s3_delete[0]: Creation complete after 1s [id=SerratusIamRole-serratus-align:S3DeleteData-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.s3_write: Creation complete after 1s [id=SerratusIamRole-serratus-align:S3WriteData-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.s3_write: Creation complete after 1s [id=SerratusIamRole-serratus-dl:S3WriteData-serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"out\"]: Creation complete after 1s [id=tf-serratus-work-20200507200447766300000002:prefix-out]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"bam-blocks\"]: Creation complete after 1s [id=tf-serratus-work-20200507200447766300000002:prefix-bam-blocks]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.s3_write: Creation complete after 1s [id=SerratusIamRole-serratus-merge:S3WriteData-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.s3_delete[0]: Creation complete after 1s [id=SerratusIamRole-serratus-merge:S3DeleteData-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.full: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.full: Creation complete after 2s [id=tf-serratus-work-20200507200447766300000002:full]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_cluster.monitor: Still creating... [10s elapsed]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_instance.scheduler: Still creating... [10s elapsed]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_cluster.monitor: Creation complete after 11s [id=arn:aws:ecs:us-east-1:797308887321:cluster/serratus-monitor]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_instance.monitor: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_instance.scheduler: Creation complete after 16s [id=i-05b4ae34796b9f53f]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_eip.sch: Modifying... [id=eipalloc-0720a99b224a4f36f]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_task_definition.monitor: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_task_definition.monitor: Creation complete after 1s [id=monitor]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_service.monitor: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_service.monitor: Creation complete after 1s [id=arn:aws:ecs:us-east-1:797308887321:service/serratus-monitor]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_eip.sch: Modifications complete after 2s [id=eipalloc-0720a99b224a4f36f]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_launch_configuration.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_launch_configuration.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_launch_configuration.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_launch_configuration.worker: Creation complete after 2s [id=serratus-dl-20200507200506532800000009]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_launch_configuration.worker: Creation complete after 2s [id=serratus-align-20200507200506525900000008]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_group.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_autoscaling_group.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_launch_configuration.worker: Creation complete after 2s [id=serratus-merge-2020050720050653610000000a]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_autoscaling_group.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_instance.monitor: Still creating... [10s elapsed]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_group.worker: Creation complete after 1s [id=serratus-dl-20200507200506532800000009]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.dl_set_capacity: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.dl_set_capacity: Creation complete after 0s [id=66e4c8f581cc904cc1ad194d825d3763aa2d0612]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_policy.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_autoscaling_group.worker: Creation complete after 1s [id=serratus-align-20200507200506525900000008]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.align_set_capacity: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.align_set_capacity: Creation complete after 0s [id=09d794f787c1d2503544a5f07751d28fb7908071]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_autoscaling_policy.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_autoscaling_group.worker: Creation complete after 1s [id=serratus-merge-2020050720050653610000000a]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.merge_set_capacity: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.merge_set_capacity: Creation complete after 0s [id=97f829d43807856215b04e365409d31bbb34d493]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_autoscaling_policy.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_autoscaling_policy.worker: Creation complete after 1s [id=serratus-align-20200507200506525900000008]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_policy.worker: Creation complete after 1s [id=serratus-dl-20200507200506532800000009]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_launch_configuration.worker: Destroying... [id=serratus-dl-20200507150922838300000008]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_autoscaling_policy.worker: Creation complete after 2s [id=serratus-merge-2020050720050653610000000a]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_launch_configuration.worker: Destruction complete after 1s\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_instance.monitor: Creation complete after 16s [id=i-06cc1e939b6205b0e]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_eip.monitor: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_eip.monitor: Creation complete after 2s [id=eipalloc-0bcdfef8667758f13]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.create_tunnel: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.hosts: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.hosts: Creation complete after 0s [id=76dac02d58033a8c9a5d8d98c71feec5616cb739]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.create_tunnel: Creation complete after 0s [id=173aceb393cd854e9b2d642ee00516e88a48e26a]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1m\u001b[32m\r\n",
      "Apply complete! Resources: 59 added, 1 changed, 1 destroyed.\u001b[0m\r\n",
      "\u001b[0m\u001b[1m\u001b[32m\r\n",
      "Outputs:\r\n",
      "\r\n",
      "align_asg_name = serratus-align-20200507200506525900000008\r\n",
      "dl_asg_name = serratus-dl-20200507200506532800000009\r\n",
      "help = Run ./create_tunnels.sh to create SSH tunnels for all services.\r\n",
      "\r\n",
      "merge_asg_name = serratus-merge-2020050720050653610000000a\r\n",
      "monitor_dns = ec2-3-82-31-43.compute-1.amazonaws.com\r\n",
      "scheduler_dns = ec2-52-6-18-10.compute-1.amazonaws.com\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "cd $TF\n",
    "# Launch Terraform Cluster\n",
    "# Initialize the serratus cluster with minimal nodes\n",
    "terraform apply -auto-approve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Serratus \n",
    "Upload the run data, scale-out the cluster, monitor performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Monitors & Upload table\n",
    "Open SSH tunnels to monitor node then open monitors in browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunnels created:\r\n",
      "Warning: Permanently added 'ec2-3-82-31-43.compute-1.amazonaws.com,3.82.31.43' (ECDSA) to the list of known hosts.\r",
      "\r\n",
      "    localhost:3000 -- grafana\r\n",
      "Warning: Permanently added 'ec2-3-82-31-43.compute-1.amazonaws.com,3.82.31.43' (ECDSA) to the list of known hosts.\r",
      "\r\n",
      "    localhost:9090 -- prometheus\r\n",
      "Warning: Permanently added 'ec2-52-6-18-10.compute-1.amazonaws.com,52.6.18.10' (ECDSA) to the list of known hosts.\r",
      "\r\n",
      "    localhost:8000 -- scheduler\r\n"
     ]
    }
   ],
   "source": [
    "cd $TF\n",
    "\n",
    "# Open SSH tunnels to the monitor\n",
    "./create_tunnels.sh\n",
    "\n",
    "# Download Scheduler config file\n",
    "#curl localhost:8000/config > serratus-config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "\"ALIGN_ARGS\":\"--very-sensitive-local\",\r\n",
      "\"ALIGN_SCALING_CONSTANT\":0.1,\r\n",
      "\"ALIGN_SCALING_ENABLE\":true,\r\n",
      "\"ALIGN_SCALING_MAX\":0,\r\n",
      "\"CLEAR_INTERVAL\":300,\r\n",
      "\"DL_ARGS\":\"\",\r\n",
      "\"DL_SCALING_CONSTANT\":0.1,\r\n",
      "\"DL_SCALING_ENABLE\":true,\r\n",
      "\"DL_SCALING_MAX\":0,\r\n",
      "\"GENOME\":\"cov2r\",\r\n",
      "\"MERGE_ARGS\":\"\",\r\n",
      "\"MERGE_SCALING_CONSTANT\":0.1,\r\n",
      "\"MERGE_SCALING_ENABLE\":true,\r\n",
      "\"MERGE_SCALING_MAX\":0,\r\n",
      "\"SCALING_INTERVAL\":300\r\n",
      "}\r\n",
      "--------\r\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0{\"ALIGN_ARGS\":\"--very-sensitive-local\",\"ALIGN_SCALING_CONSTANT\":0.1,\"ALIGN_SCALING_ENABLE\":true,\"ALIGN_SCALING_MAX\":0,\"CLEAR_INTERVAL\":300,\"DL_ARGS\":\"\",\"DL_SCALING_CONSTANT\":0.1,\"DL_SCALING_ENABLE\":true,\"DL_SCALING_MAX\":0,\"GENOME\":\"cov2r\",\"MERGE_ARGS\":\"\",\"MERGE_SCALING_CONSTANT\":0.1,\"MERGE_SCALING_ENABLE\":true,\"MERGE_SCALING_MAX\":0,\"SCALING_INTERVAL\":300}\r\n",
      "\r",
      "100   732  100   358  100   374   1340   1400 --:--:-- --:--:-- --:--:--  2741\r\n"
     ]
    }
   ],
   "source": [
    "cd $TF\n",
    "# Make local changes to config file\n",
    "cat serratus-config.json\n",
    "echo '--------'\n",
    "# Re-upload config file\n",
    "curl -T serratus-config.json localhost:8000/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"inserted_rows\":5000,\"total_rows\":5000}\r\n"
     ]
    }
   ],
   "source": [
    "# Load SRA Run Info into scheduler (READY) BATCH 2\n",
    "curl -s -X POST -T $RUNINFO localhost:8000/jobs/add_sra_run_info/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale up the cluster\n",
    "\n",
    "Cluster scale-in and scale-out is automated. Should be \"set it and forget it\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\r\n",
      "<title>400 Bad Request</title>\r\n",
      "<h1>Bad Request</h1>\r\n",
      "<p>The browser (or proxy) sent a request that this server could not understand.</p>\r\n"
     ]
    }
   ],
   "source": [
    "# Error fixes (manually help along)\n",
    "\n",
    "# Reset Split_err\n",
    "# sqlite3 instance/scheduler.sqlite 'UPDATE blocks SET state = \"new\" WHERE state = \"aligning\";'\n",
    "\n",
    "# Clear DONE Accessions\n",
    "# sqlite3 instance/scheduler.sqlite 'DELETE FROM acc WHERE state = \"merge_done\";'\n",
    "# Error fixes (manually help along)\n",
    "\n",
    "#curl -X POST \"localhost:8000/jobs/split/36?state=new&N_paired=0&N_unpaired=0\"\n",
    "\n",
    "#X=36; Y=36; STATE='new';\n",
    "#for BLOCK_ID in $(seq $X $Y);\n",
    "#do\n",
    "#  curl -X POST \"localhost:8000/jobs/split/$BLOCK_ID?state=new&N_paired=0&N_unpaired=0\"\n",
    "#done\n",
    "\n",
    "#X=4218; Y=4218; STATE='new';\n",
    "#for BLOCK_ID in $(seq $X $Y);\n",
    "#do\n",
    "#  curl -X POST -s \"localhost:8000/jobs/align/$BLOCK_ID?state=$STATE\"\n",
    "#done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"inserted_rows\":5000,\"total_rows\":10000}\r\n"
     ]
    }
   ],
   "source": [
    "# Load SRA Run Info into scheduler (READY) BATCH 3\n",
    "# (use explicit calls to batch file for recordkeeping)\n",
    "# (I'm fairly certain this was the correct batch 3 file)\n",
    "curl -s -X POST -T $RUNINFO localhost:8000/jobs/add_sra_run_info/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run,ReleaseDate,LoadDate,spots,bases,spots_with_mates,avgLength,size_MB,AssemblyName,download_path,Experiment,LibraryName,LibraryStrategy,LibrarySelection,LibrarySource,LibraryLayout,InsertSize,InsertDev,Platform,Model,SRAStudy,BioProject,Study_Pubmed_id,ProjectID,Sample,BioSample,SampleType,TaxID,ScientificName,SampleName,g1k_pop_code,source,g1k_analysis_group,Subject_ID,Sex,Disease,Tumor,Affection_Status,Analyte_Type,Histological_Type,Body_Site,CenterName,Submission,dbgap_study_accession,Consent,RunHash,ReadHash\r\n",
      "SRR9716056,2019-07-19 11:40:12,2019-07-19 11:38:52,24657080,3707641479,24657080,150,1398,,https://sra-downloadb.be-md.ncbi.nlm.nih.gov/sos2/sra-pub-run-15/SRR9716056/SRR9716056.1,SRX6473909,LIB100696,RNA-Seq,RANDOM,TRANSCRIPTOMIC,PAIRED,0,0,ILLUMINA,NextSeq 500,SRP215437,PRJNA555558,,555558,SRS5122856,SAMN12322693,simple,9913,Bos taurus,LIB100696,,,,,female,,no,,,,,USDA-ARS-USMARC,SRA923269,,public,920D345C7236F4FCAC8349DE9DB052BC,A8DFCE993E130652DBBF8C6CBE0BA7A3\r\n",
      "SRR9716063,2019-07-19 11:48:11,2019-07-19 11:45:07,36122165,5429743947,36122165,150,2041,,https://sra-downloadb.be-md.ncbi.nlm.nih.gov/sos2/sra-pub-run-15/SRR9716063/SRR9716063.1,SRX6473902,LIB100697,RNA-Seq,RANDOM,TRANSCRIPTOMIC,PAIRED,0,0,ILLUMINA,NextSeq 500,SRP215437,PRJNA555558,,555558,SRS5122849,SAMN12322694,simple,9913,Bos taurus,LIB100697,,,,,female,,no,,,,,USDA-ARS-USMARC,SRA923269,,public,E054FFA27F439A4072DB9C35D5296844,AFA07966E41E5C16013BBD8438DA6A05\r\n"
     ]
    }
   ],
   "source": [
    "head -n 3 \"$WORK/batch3_zoonotic.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"inserted_rows\":5000,\"total_rows\":15000}\r\n"
     ]
    }
   ],
   "source": [
    "# Load SRA Run Info BATCH 4\n",
    "curl -s -X POST -T \"$WORK/batch4_zoonotic.csv\" localhost:8000/jobs/add_sra_run_info/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"inserted_rows\":10000,\"total_rows\":25000}\r\n"
     ]
    }
   ],
   "source": [
    "# Load SRA Run Info BATCH 5\n",
    "curl -s -X POST -T \"$WORK/batch5_zoonotic.csv\" localhost:8000/jobs/add_sra_run_info/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Shutting down procedures\n",
    "\n",
    "Closing up shop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May  7 17:08:01 PDT 2020\r\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  1 20.9M    1  304k    0     0   412k      0  0:00:52 --:--:--  0:00:52  411k\r",
      "  6 20.9M    6 1472k    0     0   877k      0  0:00:24  0:00:01  0:00:23  876k\r",
      " 12 20.9M   12 2720k    0     0  1013k      0  0:00:21  0:00:02  0:00:19 1013k\r",
      " 18 20.9M   18 4032k    0     0  1096k      0  0:00:19  0:00:03  0:00:16 1095k\r",
      " 23 20.9M   23 5120k    0     0  1093k      0  0:00:19  0:00:04  0:00:15 1093k\r",
      " 29 20.9M   29 6400k    0     0  1127k      0  0:00:19  0:00:05  0:00:14 1234k\r",
      " 36 20.9M   36 7744k    0     0  1158k      0  0:00:18  0:00:06  0:00:12 1252k\r",
      " 42 20.9M   42 9120k    0     0  1187k      0  0:00:18  0:00:07  0:00:11 1281k\r",
      " 48 20.9M   48 10.2M    0     0  1210k      0  0:00:17  0:00:08  0:00:09 1294k\r",
      " 55 20.9M   55 11.6M    0     0  1238k      0  0:00:17  0:00:09  0:00:08 1374k\r",
      " 63 20.9M   63 13.2M    0     0  1273k      0  0:00:16  0:00:10  0:00:06 1438k\r",
      " 69 20.9M   69 14.6M    0     0  1282k      0  0:00:16  0:00:11  0:00:05 1449k\r",
      " 76 20.9M   76 16.0M    0     0  1297k      0  0:00:16  0:00:12  0:00:04 1467k\r",
      " 83 20.9M   83 17.5M    0     0  1309k      0  0:00:16  0:00:13  0:00:03 1480k\r",
      " 91 20.9M   91 19.1M    0     0  1334k      0  0:00:16  0:00:14  0:00:02 1520k\r",
      " 96 20.9M   96 20.2M    0     0  1323k      0  0:00:16  0:00:15  0:00:01 1430k\r",
      "100 20.9M  100 20.9M    0     0  1306k      0  0:00:16  0:00:16 --:--:-- 1364k\r\n"
     ]
    }
   ],
   "source": [
    "# Dump the Scheduler SQLITE table to a local file\n",
    "date\n",
    "curl localhost:8000/db > \\\n",
    "  $WORK/zoonotic_batch2_checkpoint.sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May  7 18:48:45 PDT 2020\r\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0 28.7M    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  2 28.7M    2  592k    0     0   467k      0  0:01:02  0:00:01  0:01:01  467k\r",
      "  6 28.7M    6 1792k    0     0   783k      0  0:00:37  0:00:02  0:00:35  783k\r",
      " 10 28.7M   10 3104k    0     0   945k      0  0:00:31  0:00:03  0:00:28  944k\r",
      " 15 28.7M   15 4480k    0     0  1049k      0  0:00:28  0:00:04  0:00:24 1049k\r",
      " 20 28.7M   20 5984k    0     0  1133k      0  0:00:25  0:00:05  0:00:20 1272k\r",
      " 25 28.7M   25 7456k    0     0  1189k      0  0:00:24  0:00:06  0:00:18 1372k\r",
      " 30 28.7M   30 9024k    0     0  1242k      0  0:00:23  0:00:07  0:00:16 1453k\r",
      " 36 28.7M   36 10.4M    0     0  1293k      0  0:00:22  0:00:08  0:00:14 1522k\r",
      " 41 28.7M   41 11.8M    0     0  1305k      0  0:00:22  0:00:09  0:00:13 1523k\r",
      " 46 28.7M   46 13.3M    0     0  1324k      0  0:00:22  0:00:10  0:00:12 1526k\r",
      " 51 28.7M   51 14.9M    0     0  1357k      0  0:00:21  0:00:11  0:00:10 1568k\r",
      " 57 28.7M   57 16.6M    0     0  1387k      0  0:00:21  0:00:12  0:00:09 1597k\r",
      " 63 28.7M   63 18.3M    0     0  1413k      0  0:00:20  0:00:13  0:00:07 1613k\r",
      " 69 28.7M   69 19.9M    0     0  1433k      0  0:00:20  0:00:14  0:00:06 1671k\r",
      " 75 28.7M   75 21.7M    0     0  1458k      0  0:00:20  0:00:15  0:00:05 1735k\r",
      " 82 28.7M   82 23.6M    0     0  1487k      0  0:00:19  0:00:16  0:00:03 1779k\r",
      " 88 28.7M   88 25.3M    0     0  1500k      0  0:00:19  0:00:17  0:00:02 1777k\r",
      " 93 28.7M   93 27.0M    0     0  1512k      0  0:00:19  0:00:18  0:00:01 1773k\r",
      "100 28.7M  100 28.7M    0     0  1532k      0  0:00:19  0:00:19 --:--:-- 1818k\r\n"
     ]
    }
   ],
   "source": [
    "# Dump the Scheduler SQLITE table to a local file\n",
    "date\n",
    "curl localhost:8000/db > \\\n",
    "  $WORK/zoonotic_batch3_checkpoint.sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May  7 21:20:05 PDT 2020\r\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\r",
      "  0 46.0M    0 16384    0     0   8710      0  1:32:25  0:00:01  1:32:24  8705\r",
      "  1 46.0M    1  816k    0     0   310k      0  0:02:31  0:00:02  0:02:29  310k\r",
      "  4 46.0M    4 2112k    0     0   582k      0  0:01:20  0:00:03  0:01:17  582k\r",
      "  7 46.0M    7 3424k    0     0   741k      0  0:01:03  0:00:04  0:00:59  741k\r",
      " 10 46.0M   10 4832k    0     0   860k      0  0:00:54  0:00:05  0:00:49 1093k\r",
      " 13 46.0M   13 6336k    0     0   956k      0  0:00:49  0:00:06  0:00:43 1331k\r",
      " 16 46.0M   16 7776k    0     0  1019k      0  0:00:46  0:00:07  0:00:39 1391k\r",
      " 19 46.0M   19 9120k    0     0  1056k      0  0:00:44  0:00:08  0:00:36 1399k\r",
      " 22 46.0M   22 10.3M    0     0  1101k      0  0:00:42  0:00:09  0:00:33 1433k\r",
      " 25 46.0M   25 11.9M    0     0  1150k      0  0:00:41  0:00:10  0:00:31 1476k\r",
      " 29 46.0M   29 13.4M    0     0  1187k      0  0:00:39  0:00:11  0:00:28 1493k\r",
      " 31 46.0M   31 14.7M    0     0  1194k      0  0:00:39  0:00:12  0:00:27 1461k\r",
      " 34 46.0M   34 16.0M    0     0  1204k      0  0:00:39  0:00:13  0:00:26 1460k\r",
      " 38 46.0M   38 17.5M    0     0  1227k      0  0:00:38  0:00:14  0:00:24 1469k\r",
      " 41 46.0M   41 19.0M    0     0  1248k      0  0:00:37  0:00:15  0:00:22 1456k\r",
      " 44 46.0M   44 20.6M    0     0  1272k      0  0:00:37  0:00:16  0:00:21 1472k\r",
      " 48 46.0M   48 22.2M    0     0  1292k      0  0:00:36  0:00:17  0:00:19 1541k\r",
      " 51 46.0M   51 23.9M    0     0  1314k      0  0:00:35  0:00:18  0:00:17 1613k\r",
      " 55 46.0M   55 25.6M    0     0  1340k      0  0:00:35  0:00:19  0:00:16 1670k\r",
      " 59 46.0M   59 27.5M    0     0  1368k      0  0:00:34  0:00:20  0:00:14 1744k\r",
      " 64 46.0M   64 29.6M    0     0  1403k      0  0:00:33  0:00:21  0:00:12 1836k\r",
      " 68 46.0M   68 31.4M    0     0  1422k      0  0:00:33  0:00:22  0:00:11 1879k\r",
      " 72 46.0M   72 33.5M    0     0  1453k      0  0:00:32  0:00:23  0:00:09 1974k\r",
      " 76 46.0M   76 35.3M    0     0  1468k      0  0:00:32  0:00:24  0:00:08 1966k\r",
      " 79 46.0M   79 36.7M    0     0  1468k      0  0:00:32  0:00:25  0:00:07 1884k\r",
      " 82 46.0M   82 37.8M    0     0  1453k      0  0:00:32  0:00:26  0:00:06 1668k\r",
      " 84 46.0M   84 38.9M    0     0  1441k      0  0:00:32  0:00:27  0:00:05 1530k\r",
      " 86 46.0M   86 40.0M    0     0  1432k      0  0:00:32  0:00:28  0:00:04 1333k\r",
      " 89 46.0M   89 41.2M    0     0  1425k      0  0:00:33  0:00:29  0:00:04 1217k\r",
      " 92 46.0M   92 42.5M    0     0  1424k      0  0:00:33  0:00:30  0:00:03 1197k\r",
      " 95 46.0M   95 44.0M    0     0  1426k      0  0:00:33  0:00:31  0:00:02 1279k\r",
      " 98 46.0M   98 45.5M    0     0  1430k      0  0:00:32  0:00:32 --:--:-- 1367k\r",
      "100 46.0M  100 46.0M    0     0  1432k      0  0:00:32  0:00:32 --:--:-- 1429k\r\n"
     ]
    }
   ],
   "source": [
    "# Dump the Scheduler SQLITE table to a local file\n",
    "date\n",
    "curl localhost:8000/db > \\\n",
    "  $WORK/zoonotic_batch4_checkpoint.sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May  7 23:24:11 PDT 2020\r\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  1 61.6M    1  640k    0     0   787k      0  0:01:20 --:--:--  0:01:20  786k\r",
      "  3 61.6M    3 2208k    0     0  1199k      0  0:00:52  0:00:01  0:00:51 1198k\r",
      "  5 61.6M    5 3744k    0     0  1320k      0  0:00:47  0:00:02  0:00:45 1320k\r",
      "  7 61.6M    7 5024k    0     0  1317k      0  0:00:47  0:00:03  0:00:44 1317k\r",
      "  9 61.6M    9 6112k    0     0  1270k      0  0:00:49  0:00:04  0:00:45 1270k\r",
      " 11 61.6M   11 7232k    0     0  1241k      0  0:00:50  0:00:05  0:00:45 1315k\r",
      " 13 61.6M   13 8224k    0     0  1202k      0  0:00:52  0:00:06  0:00:46 1203k\r",
      " 14 61.6M   14 9312k    0     0  1191k      0  0:00:52  0:00:07  0:00:45 1117k\r",
      " 16 61.6M   16 10.2M    0     0  1190k      0  0:00:53  0:00:08  0:00:45 1092k\r",
      " 18 61.6M   18 11.4M    0     0  1188k      0  0:00:53  0:00:09  0:00:44 1109k\r",
      " 20 61.6M   20 12.6M    0     0  1196k      0  0:00:52  0:00:10  0:00:42 1144k\r",
      " 22 61.6M   22 14.0M    0     0  1211k      0  0:00:52  0:00:11  0:00:41 1223k\r",
      " 25 61.6M   25 15.4M    0     0  1233k      0  0:00:51  0:00:12  0:00:39 1299k\r",
      " 27 61.6M   27 16.7M    0     0  1243k      0  0:00:50  0:00:13  0:00:37 1337k\r",
      " 29 61.6M   29 18.0M    0     0  1246k      0  0:00:50  0:00:14  0:00:36 1360k\r",
      " 30 61.6M   30 19.0M    0     0  1231k      0  0:00:51  0:00:15  0:00:36 1307k\r",
      " 32 61.6M   32 20.1M    0     0  1228k      0  0:00:51  0:00:16  0:00:35 1269k\r",
      " 34 61.6M   34 21.3M    0     0  1227k      0  0:00:51  0:00:17  0:00:34 1213k\r",
      " 36 61.6M   36 22.6M    0     0  1231k      0  0:00:51  0:00:18  0:00:33 1197k\r",
      " 38 61.6M   38 23.5M    0     0  1215k      0  0:00:51  0:00:19  0:00:32 1124k\r",
      " 39 61.6M   39 24.3M    0     0  1198k      0  0:00:52  0:00:20  0:00:32 1091k\r",
      " 41 61.6M   41 25.2M    0     0  1185k      0  0:00:53  0:00:21  0:00:32 1043k\r",
      " 42 61.6M   42 26.2M    0     0  1179k      0  0:00:53  0:00:22  0:00:31 1006k\r",
      " 44 61.6M   44 27.3M    0     0  1176k      0  0:00:53  0:00:23  0:00:30  972k\r",
      " 46 61.6M   46 28.5M    0     0  1178k      0  0:00:53  0:00:24  0:00:29 1032k\r",
      " 48 61.6M   48 29.8M    0     0  1185k      0  0:00:53  0:00:25  0:00:28 1130k\r",
      " 50 61.6M   50 31.2M    0     0  1186k      0  0:00:53  0:00:26  0:00:27 1187k\r",
      " 52 61.6M   52 32.2M    0     0  1186k      0  0:00:53  0:00:27  0:00:26 1216k\r",
      " 53 61.6M   53 33.2M    0     0  1180k      0  0:00:53  0:00:28  0:00:25 1199k\r",
      " 55 61.6M   55 34.2M    0     0  1176k      0  0:00:53  0:00:29  0:00:24 1166k\r",
      " 57 61.6M   57 35.4M    0     0  1177k      0  0:00:53  0:00:30  0:00:23 1139k\r",
      " 59 61.6M   59 36.5M    0     0  1174k      0  0:00:53  0:00:31  0:00:22 1112k\r",
      " 60 61.6M   60 37.4M    0     0  1167k      0  0:00:54  0:00:32  0:00:22 1066k\r",
      " 62 61.6M   62 38.5M    0     0  1167k      0  0:00:54  0:00:33  0:00:21 1089k\r",
      " 64 61.6M   64 39.7M    0     0  1169k      0  0:00:53  0:00:34  0:00:19 1128k\r",
      " 66 61.6M   66 41.0M    0     0  1172k      0  0:00:53  0:00:35  0:00:18 1136k\r",
      " 68 61.6M   68 42.0M    0     0  1168k      0  0:00:54  0:00:36  0:00:18 1124k\r",
      " 69 61.6M   69 43.0M    0     0  1164k      0  0:00:54  0:00:37  0:00:17 1146k\r",
      " 71 61.6M   71 44.2M    0     0  1167k      0  0:00:54  0:00:38  0:00:16 1168k\r",
      " 73 61.6M   73 45.5M    0     0  1170k      0  0:00:53  0:00:39  0:00:14 1172k\r",
      " 75 61.6M   75 46.7M    0     0  1172k      0  0:00:53  0:00:40  0:00:13 1178k\r",
      " 78 61.6M   78 48.1M    0     0  1178k      0  0:00:53  0:00:41  0:00:12 1253k\r",
      " 80 61.6M   80 49.5M    0     0  1185k      0  0:00:53  0:00:42  0:00:11 1337k\r",
      " 82 61.6M   82 51.1M    0     0  1194k      0  0:00:52  0:00:43  0:00:09 1410k\r",
      " 84 61.6M   84 52.2M    0     0  1202k      0  0:00:52  0:00:44  0:00:08 1478k\r\n",
      "curl: (18) transfer closed with 9846784 bytes remaining to read\r\n"
     ]
    }
   ],
   "source": [
    "# Dump the Scheduler SQLITE table to a local file -- Network death\n",
    "# There are no errors, either networking on AWS hit some quota and we died\n",
    "# or SRA cut the line and we died.\n",
    "# Last message was\n",
    "date\n",
    "curl localhost:8000/db > \\\n",
    "  $WORK/zoonotic_batch5_checkpoint.sqlite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Accession `SRR7733541` sra-dump died with...\n",
    "\n",
    "```\n",
    "2020-05-08T04:49:39 fastq-dump.2.10.4 err: error unknown while creating file within network system module - error with https open 'https://locate.ncbi.nlm.nih.gov/sdlr/sdlr.fcgi?jwt=eyJhbGciOiJSUzI1NiIsImtpZCI6InNkbGtpZDEiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE1ODg5MTMzMTIsImlhdCI6MTU4ODkwOTcxMiwibGluayI6Imh0dHBzOi8vc3JhLXB1Yi1ydW4tMS5zMy5hbWF6b25hd3MuY29tL1NSUjc3MzM1NDEvU1JSNzczMzU0MS4xP25jYmlfcGhpZD05MzlCNTM3NzcyQkFBMTY1MDAwMDQyN0IzMzQ1ODU0NS4xLjEmeC1hbXotcmVxdWVzdC1wYXllcj1yZXF1ZXN0ZXIiLCJyZWdpb24iOiJ1cy1lYXN0LTEiLCJzZXJ2aWNlIjoiczMiLCJzaWduaW5nQWNjb3VudCI6InNyYV9zMyIsInRpbWVvdXQiOjYwMDB9.Zlf-5hKRqjYr_A6g7v-2ElkZoDhttCh1febO6F0YcFyGiDGg1pt9xhMJ8LZjNy0RHsYQWCrcC_YBWSQL4wpqNzziuiII7KxGqIKeDTyqyDB4qqcAFynK-fpgPNr1yzmc0rdnMPM9uTltmM8jBlcUHOEh8qmws9WFCK9SG4uGqHOASaX8EhuYyCY1Gn-i51ibLd6VCsHx0AuFOaWjVXLFWDc8SoEjNAvOocXrkqU9Izadx3DE5smA-ZNoWtvAD_q0uTokOmpUpp8hw248iUjHaAEhUvAoylu_QZ68zPPNYOITLzVHcPtOB20SrxdQSDZg1vgIecmsQrOdMI1Aa1XQ8Q'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Destroy Cluster\n",
    "\n",
    "Close out all resources with terraform (will take a few minutes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terraform destroy -auto-approve\n",
    "# WARNING this will also delete the standard output bucket/data\n",
    "# Save data prior to destroy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Notes\n",
    "\n",
    "Completed Accessions: `10548`\n",
    "\n",
    "#### Recurrent split error\n",
    "10 Entries: `ERR3403501` - `ERR3403510`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
